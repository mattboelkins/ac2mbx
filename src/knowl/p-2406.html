<!--**************************************-->
<!--* Generated from MathBook XML source *-->
<!--*    on 2016-04-29T09:40:50-07:00    *-->
<!--*                                    *-->
<!--*   http://mathbook.pugetsound.edu   *-->
<!--*                                    *-->
<!--**************************************-->
<article class="paragraph"><h5 xmlns:b64="https://github.com/ilyakharlamov/xslt_base64" class="heading"><span class="type">Paragraph</span></h5>
The Ratio Test tells us how we can determine the set of \(x\) values for which a Taylor series converges absolutely. However, just because a Taylor series for a function \(f\) converges, we cannot be certain that the Taylor series actually converges to \(f(x)\) on its interval of convergence. To show why and where a Taylor series does in fact converge to the function \(f\), we next consider the error that is present in Taylor polynomials.
</article><span class="incontext"><a href="S_8.5.Taylor.html#p-2406">in-context</a></span>
