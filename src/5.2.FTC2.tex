\section{The Second Fundamental Theorem of Calculus} \label{S:5.2.FTC2}

\vspace*{-14 pt}
\framebox{\hspace*{3 pt}
\parbox{\boxwidth}{\begin{goals}
\item How does the integral function $A(x) = \int_1^x f(t) \, dt$ define an antiderivative of $f$?
\item What is the statement of the Second Fundamental Theorem of Calculus?
\item How do the First and Second Fundamental Theorems of Calculus enable us to formally see how differentiation and integration are almost inverse processes?
\end{goals}} \hspace*{3 pt}}

\subsection*{Introduction}

In Section~\ref{S:4.4.FTC}, we learned the Fundamental Theorem of Calculus (FTC), which from here forward will be referred to as the \emph{First} Fundamental Theorem of Calculus\index{Fundamental Theorem of Calculus!First}, as in this section we develop a corresponding result that follows it.  In particular, recall that the First FTC tells us that if $f$ is a continuous function on $[a,b]$ and $F$ is any antiderivative of $f$ (that is, $F' = f$), then
$$\int_a^b f(x) \, dx = F(b) - F(a).$$
We have typically used this result in two settings:  (1) where $f$ is a function whose graph we know and for which we can compute the exact area bounded by $f$ on a certain interval $[a,b]$, we can compute the change in an antiderivative $F$ over the interval; and (2) where $f$ is a function for which it is easy to determine an algebraic formula for an antiderivative, we may evaluate the integral exactly and hence determine the net-signed area bounded by the function on the interval.   For the former, see Preview Activity~\ref{PA:5.1} or Activity~\ref{A:5.1.1}.  For the latter, we can easily evaluate exactly integrals such as
$$\int_1^4 x^2 \, dx,$$
since we know that the function $F(x) = \frac{1}{3}x^3$ is an antiderivative of $f(x) = x^2$.  Thus,
\begin{eqnarray*}
\int_1^4 x^2 \, dx & = & \frac{1}{3}x^3 \bigg\vert_1^4 \\
			& = & \frac{1}{3}(4)^3 - \frac{1}{3}(1)^3 \\
			& = & 21.
\end{eqnarray*}
Here we see that the First FTC can be viewed from at least two perspectives:  first, as a tool to find the difference $F(b) - F(a)$ for an antiderivative $F$ of the integrand $f$.  In this situation, we need to be able to determine the value of the integral $\int_a^b f(x) \, dx$ exactly, perhaps through known geometric formulas for area.  It is possible that we may not have a formula for $F$ itself.  From a second perspective, the First FTC provides a way to find the exact value of a definite integral, and hence a certain net-signed area exactly, by finding an antiderivative of the integrand and evaluating its total change over the interval.  In this latter case, we need to know a formula for the antiderivative $F$, as this enables us to compute net-signed areas exactly through definite integrals, as demonstrated in Figure~\ref{F:5.2.Intro}.  

\begin{figure}[h]
\begin{center}
\includegraphics{figures/5_2_Intro.eps}
\end{center}
\caption{At left, the graph of $f(x) = x^2$ on the interval $[1,4]$ and the area it bounds.  At right, the antiderivative function $F(x) = \frac{1}{3}x^3$, whose total change on $[1,4]$ is the value of the definite integral at left.} \label{F:5.2.Intro}
\end{figure}

We recall further that the value of a definite integral may have additional meaning depending on context:  change in position when the integrand is a velocity function, total pollutant leaked from a tank when the integrand is the rate at which pollution is leaking, or other total changes that correspond to a given rate function that is the integrand.  In addition, the value of the definite integral is always connected to the average value of a continuous function on a given interval:  $f_{\mbox{\tiny{AVG}}[a,b]} = \frac{1}{b-a} \int_a^b f(x) \, dx$.

Next, remember that in the last part of Section~\ref{S:5.1.AntiDGraphs}, we studied integral functions of the form $A(x) = \int_c^x f(t) \, dt$.  Figure~\ref{F:5.1.IntFxn} is a particularly important image to keep in mind as we work with integral functions, and the corresponding java applet at \href{http://gvsu.edu/s/cz}{\texttt{http://gvsu.edu/s/cz}} is likewise foundational to our understanding of the function $A$.  In what follows, we use the First FTC to gain additional understanding of the function $A(x) = \int_c^x f(t) \, dt$, where the integrand $f$ is given (either through a graph or a formula), and $c$ is a constant.  In particular, we investigate further the special nature of the relationship between the functions $A$ and $f$.	

\input{previews/5.2.PA1}

\subsection*{The Second Fundamental Theorem of Calculus}\index{Fundamental Theorem of Calculus!Second}

The result of Preview Activity~\ref{PA:5.2} is not particular to the function $f(t) = 4-2t$, nor to the choice of ``$1$'' as the lower bound in the integral that defines the function $A$.  For instance, if we let $f(t) = \cos(t) - t$ and set $A(x) = \int_2^x f(t) \, dt$, then we can determine a formula for $A$ without integrals by the First FTC.  Specifically,
\begin{eqnarray*}
A(x) & = & \int_2^x (\cos(t) - t) \, dt \\
	& = & \sin(t) - \frac{1}{2}t^2 \bigg\vert_2^x \\
	& = & \sin(x) -  \frac{1}{2}x^2 - \left(\sin(2) - 2 \right).
\end{eqnarray*}
Differentiating $A(x)$, since $(\sin(2) - 2)$ is constant, it follows that 
$$A'(x) = \cos(x) - x,$$
and thus we see that $A'(x) = f(x)$.  This tells us that for this particular choice of $f$, $A$ is an antiderivative of $f$.  More specifically, since $A(2) = \int_2^2 f(t) \, dt = 0$, $A$ is the only antiderivative of $f$ for which $A(2) = 0$.

In general, if $f$ is any continuous function, and we define the function $A$ by the rule 
$$A(x) = \int_c^x f(t) \, dt,$$
where $c$ is an arbitrary constant, then we can show that $A$ is an antiderivative of $f$.  To see why, let's demonstrate that $A'(x) = f(x)$ by using the limit definition of the derivative.  Doing so, we observe that
\begin{align}
A'(x) &= \lim_{h \to 0} \frac{A(x+h) - A(x)}{h} \notag \\
	&= \lim_{h \to 0} \frac{\int_c^{x+h} f(t) \, dt - \int_c^x f(t) \, dt}{h} \notag \\
	&= \lim_{h \to 0} \frac{\int_x^{x+h} f(t) \, dt}{h}, \label{E:FTC2limdef}
\end{align}
where Equation~(\ref{E:FTC2limdef}) in the preceding chain follows from the fact that $\int_c^x f(t) \,dt + \int_x^{x+h} f(t) \, dt = \int_c^{x+h} f(t) \, dt$.  Now, observe that for small values of $h$,
$$\int_x^{x+h} f(t) \, dt \approx f(x) \cdot h,$$
by a simple left-hand approximation of the integral.  Thus, as we take the limit in Equation~(\ref{E:FTC2limdef}), it follows that
$$A'(x) =  \lim_{h \to 0} \frac{\int_x^{x+h} f(t) \, dt}{h} = \lim_{h \to 0} \frac{f(x) \cdot h}{h} = f(x).$$

%it follows from the First FTC that
%$$A(x) = F(x) - F(c).$$
%Since $F(c)$ is constant and $F$ is an antiderivative of $f$, we see
%$$A'(x) = F'(x) = f(x),$$
%and thus $A$ is an antiderivative of $f$.  

Hence, $A$ is indeed an antiderivative of $f$.  In addition, $A(c) = \int_c^c f(t) \, dt = 0.$  The preceding argument demonstrates the truth of the Second Fundamental Theorem of Calculus, which we state as follows.

 \vspace*{5pt}
\nin \framebox{\hspace*{3 pt}
\parbox{\boxwidth}{
{\bf Theorem.}  (Second FTC) If $f$ is a continuous function and $c$ is any constant, then $f$ has a unique antiderivative $A$ that satisfies $A(c) = 0$, and that antiderivative is given by the rule $A(x) = \int_c^x f(t) \, dt$.
} \hspace*{3 pt}}
\vspace*{1pt}

\input{activities/5.2.Act1}

\subsection*{Understanding Integral Functions}%\index{}\index{}

The Second FTC provides us with a means to construct an antiderivative of any continuous function.  In particular, if we are given a continuous function $g$ and wish to find an antiderivative of $G$, we can now say that 
$$G(x) = \int_c^x g(t) \, dt$$
provides the rule for such an antiderivative, and moreover that $G(c) = 0$.  Note especially that we know that $G'(x) = g(x)$.  We sometimes want to write this relationship between $G$ and $g$ from a different notational perspective.  In particular, observe that
\begin{equation} \label{E:diffint}
\frac{d}{dx} \left[ \int_c^x g(t) \, dt \right] = g(x).
\end{equation}
This result can be particularly useful when we're given an integral function such as $G$ and wish to understand properties of its graph by recognizing that $G'(x) = g(x)$, while not necessarily being able to exactly evaluate the definite integral $\int_c^x g(t) \, dt$.  To see how this is the case, we consider the following example.

\bex  Investigate the behavior of the integral function 
$$E(x) = \int_0^x e^{-t^2} \, dt.$$
\eex
$E$ is closely related to the well known \emph{error function}\index{error functin}\footnote{The error function is defined by the rule $\mbox{erf}(x) = \frac{2}{\sqrt{\pi}} \int_0^x e^{-t^2} \,dt$ and has the key property that $0 \le \mbox{erf}(x) < 1$ for all $x \ge 0$ and moreover that $\ds \lim_{x \to \infty} \mbox{erf}(x) = 1$.}, a function that is particularly important in probability and statistics.  It turns out that the function $e^{-t^2}$ does not have an elementary antiderivative that we can express without integrals.  That is, whereas a function such as $f(t) = 4-2t$ has elementary antiderivative $F(t) = 4t - t^2$, we are unable to find a simple formula for an antiderivative of $e^{-t^2}$ that does not involve a definite integral.  We will learn more about finding (complicated) algebraic formulas for antiderivatives without definite integrals in the chapter on infinite series.

Returning our attention to the function $E$, while we cannot evaluate $E$ exactly for any value other than $x = 0$, %in part because without an algebraic antiderivative for $e^{-t^2}$ we cannot use the First FTC to evaluate the integral $\int_0^x e^{-t^2} \, dt,$ 
we still can gain a tremendous amount of information about the function $E$.  To begin, applying the rule in Equation~(\ref{E:diffint}) to $E$, it follows that
$$E'(x) = \frac{d}{dx} \left[ \int_0^x e^{-t^2} \, dt \right] = e^{-x^2},$$
so we know a formula for the derivative of $E$.  Moreover, we know that $E(0) = 0$.  This information is precisely the type we were given in problems such as the one in Activity~\ref{A:3.1.1} and others in Section~\ref{S:3.1.Tests}, where we were given information about the derivative of a function, but lacked a formula for the function itself.  

Here, using the first and second derivatives of $E$, along with the fact that $E(0) = 0$, we can determine more information about the behavior of $E$.  First, with $E'(x) = e^{-x^2}$, we note that for all real numbers $x$, $e^{-x^2} > 0$, and thus $E'(x) > 0$ for all $x$.  Thus $E$ is an always increasing function.  Further, we note that as $x \to \infty$, $E'(x) = e^{-x^2} \to 0$, hence the slope of the function $E$ tends to zero as $x \to \infty$ (and similarly as $x \to -\infty$).  Indeed, it turns out (due to some more sophisticated analysis) that $E$ has horizontal asymptotes as $x$ increases or decreases without bound. 

In addition, we can observe that $E''(x) = -2xe^{-x^2}$, and that $E''(0) = 0$, while $E''(x) < 0$ for $x > 0$ and $E''(x) > 0$ for $x < 0$.  This information tells us that $E$ is concave up for $x<0$ and concave down for $x > 0$ with a point of inflection at $x = 0$.  

The only thing we lack at this point is a sense of how big $E$ can get as $x$ increases.  If we use a midpoint Riemann sum with 10 subintervals to estimate $E(2)$, we see that $E(2) \approx 0.8822$; a similar calculation to estimate $E(3)$ shows little change ($E(3) \approx 0.8862$), so it appears that as $x$ increases without bound, $E$ approaches a value just larger than $0.886$, which aligns with the fact that $E$ has horizontal asymptotes.  Putting all of this information together (and using the symmetry of $f(t) = e^{-t^2}$), we see the results shown in Figure~\ref{F:5.2.erf}.

\begin{figure}[h]
\begin{center}
\includegraphics{figures/5_2_erf.eps}
\end{center}
\caption{At left, the graph of $f(t) = e^{-t^2}$.  At right, the integral function $E(x) = \int_0^x e^{-t^2} \,dt$, which is the unique antiderivative of $f$ that satisfies $E(0) = 0$.} \label{F:5.2.erf}
\end{figure}

Again, $E$ is the antiderivative of $f(t) = e^{-t^2}$ that satisfies $E(0) = 0$.  Moreover, the values on the graph of $y = E(x)$ represent the net-signed area of the region bounded by $f(t) = e^{-t^2}$ from 0 up to $x$.  We see that the value of $E$ increases rapidly near zero but then levels off as $x$ increases since there is less and less additional accumulated area bounded by $f(t) = e^{-t^2}$ as $x$ increases.

\afterex

\input{activities/5.2.Act2}

\subsection*{Differentiating an Integral Function}

We have seen that the Second FTC enables us to construct an antiderivative $F$ of any continuous function $f$ by defining $F$ by the corresponding integral function $F(x) = \int_c^x f(t) \, dt$.  Said differently, if we have a function of the form $F(x) = \int_c^x f(t) \, dt$, then we know that $F'(x) = \frac{d}{dx} \left[\int_c^x f(t) \, dt \right] = f(x)$.  This shows that integral functions, while perhaps having the most complicated formulas of any functions we have encountered, are nonetheless particularly simple to differentiate.  For instance, if 
$$F(x) = \int_{\pi}^x \sin(t^2) \, dt,$$
then by the Second FTC, we know immediately that
$$F'(x) = \sin(x^2).$$

Stating this result more generally for an arbitrary function $f$, we know by the Second FTC that
$$\frac{d}{dx} \left[ \int_a^x f(t) \, dt \right] = f(x).$$
In words, the last equation essentially says that ``the derivative of the integral function whose integrand is $f$, is $f$.''  In this sense, we see that if we first integrate the function $f$ from $t = a$ to $t = x$, and then differentiate with respect to $x$, these two processes ``undo'' one another.

Taking a different approach, say we begin with a function $f(t)$ and differentiate with respect to $t$.  What happens if we follow this by integrating the result from $t = a$ to $t = x$?  That is, what can we say about the quantity
$$\int_a^x \frac{d}{dt} \left[ f(t) \right] \, dt?$$
Here, we use the First FTC and note that $f(t)$ is an antiderivative of $\frac{d}{dt} \left[ f(t) \right].$  Applying this result and evaluating the antiderivative function, we see that
\begin{eqnarray*}
\int_a^x \frac{d}{dt} \left[ f(t) \right] \, dt & = & f(t) \bigg\vert_a^x \\
							& = & f(x) - f(a).
\end{eqnarray*} 
Thus, we see that if we apply the processes of first differentiating $f$ and then integrating the result from $a$ to $x$, we return to the function $f$, minus the constant value $f(a)$.  So in this situation, the two processes almost undo one another, up to the constant $f(a)$.

The observations made in the preceding two paragraphs demonstrate that differentiating and integrating (where we integrate from a constant up to a variable) are almost inverse processes.  In one sense, this should not be surprising:  integrating involves antidifferentiating, which reverses the process of differentiating.  On the other hand, we see that there is some subtlety involved, as integrating the derivative of a function does not quite produce the function itself.  This is connected to a key fact we observed in Section~\ref{S:5.1.AntiDGraphs}, which is that any function has an entire family of antiderivatives, and any two of those antiderivatives differ only by a constant.

\input{activities/5.2.Act3}

%\nin \framebox{\hspace*{3 pt}
%\parbox{6.25 in}{
\begin{summary}
\item For a continuous function $f$, the integral function $A(x) = \int_1^x f(t) \, dt$ defines an antiderivative of $f$.
\item The Second Fundamental Theorem of Calculus is the formal, more general statement of the preceding fact:  if $f$ is a continuous function and $c$ is any constant, then $A(x) = \int_c^x f(t) \, dt$ is the unique antiderivative of $f$ that satisfies $A(c) = 0$.
\item Together, the First and Second FTC enable us to formally see how differentiation and integration are almost inverse processes through the observations that
$$\int_c^x \frac{d}{dt} \left[ f(t) \right] \, dt = f(x) - f(c)$$
and
$$\frac{d}{dx} \left[ \int_c^x f(t) \, dt \right] = f(x).$$

\end{summary}
%} \hspace*{3 pt}}

\nin \hrulefill

\input{exercises/5.2.FTC2(Ex)} 

\clearpage
